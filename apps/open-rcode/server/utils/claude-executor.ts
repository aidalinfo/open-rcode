import { BaseContainerManager } from './container/base-container-manager'
import { TaskModel } from '../models/Task'
import { EnvironmentModel } from '../models/Environment'
import { PullRequestCreator } from './pull-request-creator'
import { TaskMessageModel } from '../models/TaskMessage'
import { CountRequestModel } from '../models/CountRequest'
import { UserCostModel } from '../models/UserCost'
import { v4 as uuidv4 } from 'uuid'
import { createLogger } from './logger'
import { AIProviderAdapter } from './ai-providers/ai-provider-adapter'
import { AIProviderType, ParsedOutput } from './ai-providers/base-ai-provider'
import { ContainerScripts } from './container-scripts'
import { AIProviderFactory } from './ai-providers/ai-provider-factory'

interface ExecuteResult {
  stdout: string
  stderr: string
  exitCode: number
}

export class ClaudeExecutor {
  private containerManager: BaseContainerManager
  private logger = createLogger('ClaudeExecutor')

  constructor(containerManager: BaseContainerManager) {
    this.containerManager = containerManager
  }

  async executeCommand(containerId: string, prompt: string, workdir?: string, aiProvider?: string, model?: string, task?: any, planMode?: boolean): Promise<string> {
    const providerType = (aiProvider || 'anthropic-api') as AIProviderType
    const adapter = new AIProviderAdapter(providerType)
    
    // Si nous sommes en mode plan avec Claude, utiliser executePlanCommand
    if (planMode && adapter.supportsPlanMode()) {
      return this.executePlanCommand(containerId, prompt, workdir, providerType, model, task)
    }
    
    // Si nous avons un task, utiliser executeAndSaveToolMessages pour la sauvegarde en temps r√©el
    if (task) {
      return this.executeAndSaveToolMessages(containerId, prompt, workdir || '/tmp/workspace', providerType, model || 'sonnet', task, 'Ex√©cution de commande')
    }
    
    const onOutput = (data: string) => {
      const lines = data.split('\n').filter(line => line.trim())
      lines.forEach(line => {
        if (line.trim() && !line.includes('===')) {
          this.logger.debug({ output: line.trim() }, 'ü§ñ AI output')
        }
      })
    }

    this.logger.debug({ aiProvider: providerType, model, hasAdminKey: !!process.env.ADMIN_GOOGLE_API_KEY }, 'AI Provider configuration')

    const script = adapter.buildExecutionScript({
      prompt,
      workdir: workdir || '/tmp/workspace',
      model,
      planMode
    })

    const result = await this.executeWithStreamingBash(containerId, script, onOutput)

    if (result.exitCode !== 0) {
      throw new Error(`AI command failed with exit code ${result.exitCode}: ${result.stderr || 'No stderr output'}`)
    }

    const parsedOutput = adapter.parseOutput(result.stdout)
    
    // Si c'est Gemini, retourner le r√©sultat final directement
    if (AIProviderFactory.isGeminiProvider(providerType)) {
      return parsedOutput.finalResult
    }
    
    // Pour Claude, formater la sortie
    const formattedParts: string[] = []
    
    for (const toolCall of parsedOutput.toolCalls) {
      formattedParts.push(adapter.formatToolCall(toolCall))
    }
    
    if (parsedOutput.textMessages.length > 0) {
      formattedParts.push('\nüí¨ **R√©ponse:**')
      formattedParts.push(parsedOutput.textMessages.join('\n'))
    }
    
    if (parsedOutput.finalResult && !parsedOutput.textMessages.includes(parsedOutput.finalResult)) {
      formattedParts.push('\nüìã **R√©sum√©:**')
      formattedParts.push(parsedOutput.finalResult)
    }
    
    return formattedParts.length > 0 ? formattedParts.join('\n\n') : parsedOutput.finalResult
  }

  async executeConfigurationScript(containerId: string, configScript: string, workdir?: string): Promise<string> {
    const onOutput = (data: string) => {
      const lines = data.split('\n').filter(line => line.trim())
      lines.forEach(line => {
        if (line.trim()) {
          this.logger.debug({ output: line.trim() }, 'üìã Config script output')
        }
      })
    }

    const script = ContainerScripts.buildConfigurationScript(
      workdir || '/tmp/workspace',
      configScript
    )

    const result = await this.executeWithStreamingBash(containerId, script, onOutput)

    if (result.exitCode !== 0) {
      this.logger.error({ exitCode: result.exitCode, stderr: result.stderr }, '‚ùå Configuration script failed')
      throw new Error(`Configuration script failed with exit code ${result.exitCode}: ${result.stderr || 'No stderr output'}`)
    }

    this.logger.info('‚úÖ Configuration script completed successfully')
    return result.stdout
  }

  private async executeWithStreaming(containerId: string, script: string, onOutput?: (data: string) => void): Promise<ExecuteResult> {
    // V√©rifier si c'est Kubernetes pour utiliser le streaming
    if (this.containerManager.constructor.name === 'KubernetesAdapter') {
      const kubernetesAdapter = this.containerManager as any
      if (kubernetesAdapter.executeInContainerWithStreaming) {
        return kubernetesAdapter.executeInContainerWithStreaming({
          containerId,
          command: ['sh', '-c', script],
          user: 'root',
          environment: { 'HOME': '/root' }
        }, onOutput)
      }
    }
    
    // Fallback pour Docker (pas de streaming)
    return this.containerManager.executeInContainer({
      containerId,
      command: ['sh', '-c', script],
      user: 'root',
      environment: { 'HOME': '/root' }
    })
  }

  private async executeWithStreamingBash(containerId: string, script: string, onOutput?: (data: string) => void): Promise<ExecuteResult> {
    // V√©rifier si c'est Kubernetes pour utiliser le streaming
    if (this.containerManager.constructor.name === 'KubernetesAdapter') {
      const kubernetesAdapter = this.containerManager as any
      if (kubernetesAdapter.executeInContainerWithStreaming) {
        return kubernetesAdapter.executeInContainerWithStreaming({
          containerId,
          command: ['/bin/bash', '-c', script],
          user: 'root',
          environment: { 'HOME': '/root' }
        }, onOutput)
      }
    }
    
    // Fallback pour Docker (pas de streaming)
    return this.containerManager.executeInContainer({
      containerId,
      command: ['/bin/bash', '-c', script],
      user: 'root',
      environment: { 'HOME': '/root' }
    })
  }

  async executeWorkflow(containerId: string, task: any): Promise<void> {
    const updateTaskStatus = async (status: string, error?: string) => {
      await TaskModel.findByIdAndUpdate(task._id, { 
        status, 
        error: error || null,
        updatedAt: new Date()
      });
    };

    try {
      await updateTaskStatus('running');
      this.logger.info({ taskId: task._id }, 'Starting Claude workflow');

      const environment = await EnvironmentModel.findById(task.environmentId);
      if (!environment) {
        throw new Error(`Environment ${task.environmentId} not found`);
      }

      const workspaceDir = task.workspaceDir || `/tmp/workspace/${environment.repository || 'openrcode'}`;
      const aiProvider = (environment.aiProvider || 'anthropic-api') as AIProviderType
      const model = environment.model || 'sonnet'
      this.logger.info({ workspaceDir, aiProvider, model }, 'üîß Using workspace configuration')

      if (environment.configurationScript && environment.configurationScript.trim()) {
        this.logger.info('Executing configuration script');
        try {
          const configOutput = await this.executeConfigurationScript(containerId, environment.configurationScript, workspaceDir);
          await TaskMessageModel.create({
            id: uuidv4(),
            userId: task.userId,
            taskId: task._id,
            role: 'assistant',
            content: `‚öôÔ∏è **Configuration du projet:**\n\`\`\`\n${configOutput}\n\`\`\``
          });
          this.logger.info('Configuration script completed successfully');
        } catch (configError: any) {
          this.logger.error({ error: configError.message }, 'Configuration script failed');
          await TaskMessageModel.create({
            id: uuidv4(),
            userId: task.userId,
            taskId: task._id,
            role: 'assistant',
            content: `‚ùå **Erreur lors de la configuration:**\n\`\`\`\n${configError.message}\n\`\`\``
          });
          await updateTaskStatus('failed', configError.message);
          return;
        }
      }

      const userMessage = await TaskMessageModel.findOne({ taskId: task._id, role: 'user' }).sort({ createdAt: 1 });

      let finalResult = 'T√¢che termin√©e'
      
      if (userMessage) {
        this.logger.info({ aiProvider, model, planMode: task.planMode }, 'Executing AI command with user text');
        // Cr√©er le message initial avant de commencer l'ex√©cution
        await TaskMessageModel.create({
          id: uuidv4(),
          userId: task.userId,
          taskId: task._id,
          role: 'assistant',
          content: `üöÄ **D√©marrage de l'ex√©cution avec ${this.getAiProviderLabel(aiProvider)} (${model})${task.planMode ? ' en mode plan' : ''}...**`
        });
        
        const adapter = new AIProviderAdapter(aiProvider)
        
        // Si planMode est activ√© et que le provider le supporte
        if (task.planMode && adapter.supportsPlanMode()) {
          finalResult = await this.executePlanCommand(containerId, userMessage.content, workspaceDir, aiProvider, model, task)
        } else {
          finalResult = await this.executeAndSaveToolMessages(containerId, userMessage.content, workspaceDir, aiProvider, model, task, 'Ex√©cution de la t√¢che')
        }
      }

      const prCreator = new PullRequestCreator(this.containerManager);
      await prCreator.createFromChanges(containerId, task, finalResult);

      // Cr√©er un document CountRequest pour suivre l'utilisation
      await CountRequestModel.create({
        userId: task.userId,
        environmentId: task.environmentId,
        model: model,
        taskId: task._id
      });
      this.logger.debug({ taskId: task._id }, 'CountRequest created');

      await updateTaskStatus('completed');
      this.logger.info({ taskId: task._id }, 'Claude workflow completed');

    } catch (error: any) {
      this.logger.error({ taskId: task._id, error: error.message }, 'Error in Claude workflow');
      await updateTaskStatus('failed', error.message);
      await TaskMessageModel.create({
        id: uuidv4(),
        userId: task.userId,
        taskId: task._id,
        role: 'assistant',
        content: `‚ùå **Erreur dans le workflow Claude:** ${error.message}`
      });
    } finally {
      // D√©tecter si on utilise Kubernetes
      const isKubernetes = this.containerManager.constructor.name === 'KubernetesAdapter';
      const resourceType = isKubernetes ? 'pod' : 'conteneur';
      const resourceTypeCapitalized = isKubernetes ? 'Pod' : 'Conteneur Docker';
      
      // Nettoyer le conteneur/pod apr√®s l'ex√©cution (succ√®s ou √©chec)
      this.logger.info({ taskId: task._id, resourceType }, `Cleaning up ${resourceType}`);
      try {
        await this.containerManager.removeContainer(containerId, true);
        this.logger.info({ containerId, resourceType: resourceTypeCapitalized }, 'Resource cleaned up successfully');
        
        // Supprimer la r√©f√©rence du conteneur de la t√¢che
        await TaskModel.findByIdAndUpdate(task._id, { dockerId: null });
        
        await TaskMessageModel.create({
          id: uuidv4(),
          userId: task.userId,
          taskId: task._id,
          role: 'assistant',
          content: `üßπ **Nettoyage automatique:** Le ${resourceType} a √©t√© supprim√© apr√®s l'ex√©cution de la t√¢che.`
        });
      } catch (cleanupError: any) {
        this.logger.warn({ containerId, resourceType, error: cleanupError.message }, 'Failed to cleanup resource');
        await TaskMessageModel.create({
          id: uuidv4(),
          userId: task.userId,
          taskId: task._id,
          role: 'assistant',
          content: `‚ö†Ô∏è **Attention:** √âchec du nettoyage automatique du ${resourceType}. Le ${resourceType} devra √™tre supprim√© manuellement.`
        });
      }
    }
  }


  private getAiProviderLabel(provider: AIProviderType): string {
    const adapter = new AIProviderAdapter(provider)
    return adapter.getName()
  }

  private parseClaudeJsonOutput(rawOutput: string): ParsedOutput {
    const adapter = new AIProviderAdapter('anthropic-api')
    return adapter.parseOutput(rawOutput)
  }

  private async executePlanCommand(containerId: string, prompt: string, workdir?: string, aiProvider?: AIProviderType, model?: string, task?: any): Promise<string> {
    this.logger.info('üéØ Ex√©cution en mode plan...')
    
    const providerType = aiProvider || 'anthropic-api'
    const adapter = new AIProviderAdapter(providerType)
    
    let planContent = ''
    let isInPlanMode = false
    let totalCostUsd: number | undefined
    let processedToolCallIds = new Set<string>()
    
    const onPlanOutput = async (data: string) => {
      const lines = data.split('\n').filter(line => line.trim())
      for (const line of lines) {
        if (line.trim()) {
          this.logger.debug({ output: line.trim() }, 'üìã Plan output')
          
          // Essayer de parser le JSON pour d√©tecter le mode plan et extraire le contenu
          try {
            const jsonData = JSON.parse(line.trim())
            
            // D√©tecter si on est en mode plan
            if (jsonData.type === 'system' && jsonData.permissionMode === 'plan') {
              isInPlanMode = true
              this.logger.debug('‚úÖ Mode plan activ√©')
            }
            
            // Traiter tous les tool calls (pas seulement ExitPlanMode)
            if (jsonData.type === 'assistant' && jsonData.message?.content) {
              for (const content of jsonData.message.content) {
                if (content.type === 'tool_use' && !processedToolCallIds.has(content.id)) {
                  processedToolCallIds.add(content.id)
                  
                  // Sauvegarder tous les tools, pas seulement ExitPlanMode
                  const toolCall = {
                    id: content.id,
                    name: content.name,
                    input: content.input
                  }
                  
                  // Si c'est ExitPlanMode, capturer aussi le plan
                  if (content.name === 'ExitPlanMode' && content.input?.plan) {
                    planContent = content.input.plan
                    this.logger.debug('üìÑ Plan captur√© depuis ExitPlanMode')
                  }
                  
                  // Sauvegarder le tool call dans la DB
                  if (task) {
                    const toolContent = adapter.formatToolCall(toolCall)
                    await TaskMessageModel.create({
                      id: uuidv4(),
                      userId: task.userId,
                      taskId: task._id,
                      role: 'assistant',
                      content: `ü§ñ **${adapter.getName()} (${model}) - Mode Plan:**\n\n${toolContent}`
                    })
                    
                    this.logger.debug({ toolName: content.name }, 'üíæ Tool call saved in plan mode')
                  }
                }
              }
            }
            
            // Capturer le total_cost_usd du result
            if (jsonData.type === 'result' && jsonData.total_cost_usd) {
              totalCostUsd = jsonData.total_cost_usd
              this.logger.info({ costUsd: totalCostUsd }, 'üí∞ Co√ªt total du mode plan')
            }
          } catch (parseError) {
            // Ignorer les erreurs de parsing
          }
        }
      }
    }
    
    // Phase 1: Ex√©cuter en mode plan
    const planScript = adapter.buildExecutionScript({
      prompt,
      workdir: workdir || '/tmp/workspace',
      model,
      planMode: true
    })
    
    this.logger.info('üöÄ Ex√©cution de la commande en mode plan...')
    const planResult = await this.executeWithStreamingBash(containerId, planScript, onPlanOutput)
    
    if (planResult.exitCode !== 0) {
      this.logger.error({ stderr: planResult.stderr }, '‚ùå √âchec du mode plan')
      // En cas d'√©chec, fallback sur le mode normal
      this.logger.info('‚Ü©Ô∏è Fallback sur le mode normal...')
      return this.executeAndSaveToolMessages(containerId, prompt, workdir || '/tmp/workspace', providerType, model || 'sonnet', task, 'Ex√©cution de commande')
    }
    
    // Si pas de plan captur√©, essayer de le parser depuis la sortie
    if (!planContent && planResult.stdout) {
      const lines = planResult.stdout.split('\n')
      for (const line of lines) {
        try {
          const jsonData = JSON.parse(line.trim())
          if (jsonData.type === 'assistant' && jsonData.message?.content) {
            for (const content of jsonData.message.content) {
              if (content.type === 'tool_use' && content.name === 'ExitPlanMode' && content.input?.plan) {
                planContent = content.input.plan
                break
              }
            }
          }
          // Capturer aussi le total_cost_usd depuis la sortie compl√®te
          if (jsonData.type === 'result' && jsonData.total_cost_usd && !totalCostUsd) {
            totalCostUsd = jsonData.total_cost_usd
            this.logger.info({ costUsd: totalCostUsd }, 'üí∞ Co√ªt total du mode plan (depuis la sortie)')
          }
        } catch (e) {
          // Ignorer
        }
      }
    }
    
    if (!planContent) {
      this.logger.warn('‚ö†Ô∏è Aucun plan trouv√©, ex√©cution directe du prompt...')
      return this.executeAndSaveToolMessages(containerId, prompt, workdir || '/tmp/workspace', providerType, model || 'sonnet', task, 'Ex√©cution de commande')
    }
    
    // Si on a un task, sauvegarder le plan et le co√ªt
    if (task) {
      await TaskMessageModel.create({
        id: uuidv4(),
        userId: task.userId,
        taskId: task._id,
        role: 'assistant',
        content: `üìã **Plan d'ex√©cution:**\n\n${planContent}`
      })
      
      // Sauvegarder le co√ªt du mode plan si disponible
      if (totalCostUsd) {
        try {
          await UserCostModel.create({
            environmentId: task.environmentId,
            userId: task.userId,
            taskId: task._id,
            costUsd: totalCostUsd,
            model: model === 'claude-sonnet-4' ? 'sonnet' : model || 'sonnet',
            aiProvider: providerType
          })
          this.logger.info({ costUsd: totalCostUsd, taskId: task._id }, 'üí∞ UserCost du mode plan sauvegard√©')
        } catch (costError) {
          this.logger.error({ error: costError }, 'Erreur lors de la cr√©ation du document UserCost pour le mode plan')
        }
      }
    }
    
    // Phase 2: Ex√©cuter le plan
    this.logger.info('üèÉ Ex√©cution du plan...')
    const executionPrompt = `Voici le plan √† ex√©cuter :\n\n${planContent}\n\n${prompt}`
    
    return this.executeAndSaveToolMessages(containerId, executionPrompt, workdir || '/tmp/workspace', providerType, model || 'sonnet', task, 'Ex√©cution du plan')
  }

  private formatToolCall(toolCall: any): string {
    const adapter = new AIProviderAdapter('anthropic-api')
    return adapter.formatToolCall(toolCall)
  }

  async executeAndSaveToolMessages(
    containerId: string, 
    prompt: string, 
    workdir: string, 
    aiProvider: AIProviderType, 
    model: string, 
    task: any, 
    actionLabel: string
  ): Promise<string> {
    
    const adapter = new AIProviderAdapter(aiProvider)
    const aiProviderLabel = adapter.getName()
    let streamBuffer = ''
    let processedToolCallIds = new Set<string>()
    
    // Fonction pour traiter les messages en temps r√©el
    const processStreamingOutput = async (data: string) => {
      const lines = data.split('\n').filter(line => line.trim())
      
      for (const line of lines) {
        if (line.trim() && !line.includes('===')) {
          this.logger.debug({ provider: AIProviderFactory.isGeminiProvider(aiProvider) ? 'Gemini' : 'Claude', output: line.trim() }, 'ü§ñ AI output')
          
          // Ajouter la ligne au buffer
          streamBuffer += line + '\n'
          
          // Pour Gemini, sauvegarder la sortie brute au fur et √† mesure
          if (AIProviderFactory.isGeminiProvider(aiProvider)) {
            // Ne pas essayer de parser JSON pour Gemini
            continue
          }
          
          // Pour Claude, essayer de parser les lignes JSON compl√®tes
          try {
            const jsonData = JSON.parse(line.trim())
            
            // Traiter les tool calls en temps r√©el
            if (jsonData.type === 'assistant' && jsonData.message?.content) {
              for (const content of jsonData.message.content) {
                if (content.type === 'tool_use' && !processedToolCallIds.has(content.id)) {
                  processedToolCallIds.add(content.id)
                  
                  // Cr√©er un message imm√©diatement pour ce tool call
                  const toolCall = {
                    id: content.id,
                    name: content.name,
                    input: content.input
                  }
                  
                  const toolContent = this.formatToolCall(toolCall)
                  await TaskMessageModel.create({
                    id: uuidv4(),
                    userId: task.userId,
                    taskId: task._id,
                    role: 'assistant',
                    content: `ü§ñ **${aiProviderLabel} (${model}) - ${actionLabel}:**\n\n${toolContent}`
                  })
                  
                  this.logger.debug({ toolName: content.name }, 'üíæ Tool call saved in real-time')
                }
              }
            }
          } catch (parseError) {
            // Ignorer les erreurs de parsing, la ligne n'est peut-√™tre pas du JSON
          }
        }
      }
    }
    
    // Ex√©cuter la commande AI avec le callback de streaming
    const script = adapter.buildExecutionScript({
      prompt,
      workdir,
      model,
      planMode: false
    })

    const result = await this.executeWithStreamingBash(containerId, script, processStreamingOutput)

    if (result.exitCode !== 0) {
      throw new Error(`AI command failed with exit code ${result.exitCode}: ${result.stderr || 'No stderr output'}`)
    }

    const parsedOutput = adapter.parseOutput(result.stdout)
    
    // Si c'est Gemini, g√©rer diff√©remment
    if (AIProviderFactory.isGeminiProvider(aiProvider)) {
      // Cr√©er un message avec la sortie brute de Gemini
      if (parsedOutput.finalResult.trim()) {
        await TaskMessageModel.create({
          id: uuidv4(),
          userId: task.userId,
          taskId: task._id,
          role: 'assistant',
          content: `ü§ñ **${aiProviderLabel} (${model}) - ${actionLabel}:**\n\n${parsedOutput.finalResult}`
        })
      }
      
      // Retourner la sortie pour la cr√©ation de PR
      return parsedOutput.finalResult || 'T√¢che termin√©e'
    }
    
    // Pour Claude, traiter les r√©sultats complets
    // Cr√©er un document UserCost si total_cost_usd est disponible
    if (parsedOutput.totalCostUsd) {
      try {
        await UserCostModel.create({
          environmentId: task.environmentId,
          userId: task.userId,
          taskId: task._id,
          costUsd: parsedOutput.totalCostUsd,
          model: model === 'claude-sonnet-4' ? 'sonnet' : model,
          aiProvider: aiProvider
        })
        this.logger.info({ costUsd: parsedOutput.totalCostUsd, taskId: task._id }, 'UserCost created')
      } catch (costError) {
        this.logger.error({ error: costError }, 'Error creating UserCost document')
      }
    }
    
    // Traiter les tool calls qui n'ont pas √©t√© trait√©s en temps r√©el (avec r√©sultats)
    for (const toolCall of parsedOutput.toolCalls) {
      if (!processedToolCallIds.has(toolCall.id) && toolCall.result) {
        const toolContent = this.formatToolCall(toolCall)
        await TaskMessageModel.create({
          id: uuidv4(),
          userId: task.userId,
          taskId: task._id,
          role: 'assistant',
          content: `ü§ñ **${aiProviderLabel} (${model}) - ${actionLabel}:**\n\n${toolContent}`
        })
      }
    }
    
    // Cr√©er un message pour les r√©ponses texte s'il y en a
    if (parsedOutput.textMessages.length > 0) {
      await TaskMessageModel.create({
        id: uuidv4(),
        userId: task.userId,
        taskId: task._id,
        role: 'assistant',
        content: `ü§ñ **${aiProviderLabel} (${model}) - ${actionLabel}:**\n\nüí¨ **R√©ponse:**\n${parsedOutput.textMessages.join('\n')}`
      })
    }
    
    // Cr√©er un message pour le r√©sultat final s'il est diff√©rent
    if (parsedOutput.finalResult && !parsedOutput.textMessages.includes(parsedOutput.finalResult)) {
      await TaskMessageModel.create({
        id: uuidv4(),
        userId: task.userId,
        taskId: task._id,
        role: 'assistant',
        content: `ü§ñ **${aiProviderLabel} (${model}) - ${actionLabel}:**\n\nüìã **R√©sum√©:**\n${parsedOutput.finalResult}`
      })
    }
    
    // Retourner le r√©sultat final pour la cr√©ation de PR
    return parsedOutput.finalResult || parsedOutput.textMessages.join('\n') || 'T√¢che termin√©e'
  }

  private getEnvSetup(aiProvider: string): string {
    switch (aiProvider) {
      case 'anthropic-api':
        return 'export ANTHROPIC_API_KEY="$ANTHROPIC_API_KEY"'
      case 'claude-oauth':
        return 'export CLAUDE_CODE_OAUTH_TOKEN="$CLAUDE_CODE_OAUTH_TOKEN"'
      case 'gemini-cli':
        return 'export GEMINI_API_KEY="$GEMINI_API_KEY"'
      case 'admin-gemini':
        return `export GEMINI_API_KEY="${process.env.ADMIN_GOOGLE_API_KEY}"`
      default:
        throw new Error(`Unsupported AI provider: ${aiProvider}`)
    }
  }

  private getAiCommand(aiProvider: string, model?: string): string {
    const modelParam = model ? ` --model ${model}` : ''
    
    switch (aiProvider) {
      case 'anthropic-api':
        return `claude --verbose --output-format stream-json${modelParam} -p`
      case 'claude-oauth':
        return `claude --verbose --output-format stream-json${modelParam} -p`
      case 'gemini-cli':
        return `gemini${modelParam} -p`
      case 'admin-gemini':
        return `gemini${modelParam} -p`
      default:
        throw new Error(`Unsupported AI provider: ${aiProvider}`)
    }
  }
}